# -*- coding: utf-8 -*-
"""Projeto_Titaniun_LIME_SHAP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hw8UnmTX471mSpOVdeEzGSmf3zQFWljr
"""



"""https://link.springer.com/article/10.1007/s00170-024-14597-2#Sec28"""

# Instalar uma fonte similar √† Times New Roman
!apt-get install -y fonts-liberation

# Configurar o matplotlib para usar a fonte Liberation Serif, que √© similar √† Times New Roman
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# Carregar a fonte instalada
font_path = '/usr/share/fonts/truetype/liberation/LiberationSerif-Regular.ttf'
fm.fontManager.addfont(font_path)
plt.rcParams['font.family'] = 'Liberation Serif'

import pandas as pd
import numpy as np

dados = pd.read_excel('/content/drive/MyDrive/ALEX_DOUTORADO_UNIFEI/TITANIUM/ti.xlsx')

dados.info()

df = dados

# Extrair os valores m√≠nimo e m√°ximo de vc [m/min] e f [mm/rev]
min_vc = df["vc [m/min]"].min()
max_vc = df["vc [m/min]"].max()

min_f = df["f [mm/rev]"].min()
max_f = df["f [mm/rev]"].max()

# Exibir os resultados
print(f"Cutting speed (vc) - Min: {min_vc} | Max: {max_vc}")
print(f"Feed rate (f) - Min: {min_f} | Max: {max_f}")

import pandas as pd

# Carregar os dados (supondo que j√° estejam dispon√≠veis no ambiente)
# df = pd.read_csv('dados_experimento.csv')  # Exemplo de como carregar caso estivesse em um arquivo

# Exibir um resumo dos n√≠veis de velocidade de corte (vc) e avan√ßo (f)
vc_levels = df["vc [m/min]"].unique()
f_levels = df["f [mm/rev]"].unique()

# Contar quantos n√≠veis distintos existem para vc e f
num_vc_levels = len(vc_levels)
num_f_levels = len(f_levels)

# Contar quantas combina√ß√µes √∫nicas de (vc, f) existem
num_unique_combinations = df.groupby(["vc [m/min]", "f [mm/rev]"]).ngroups

# Exibir os resultados
num_vc_levels, num_f_levels, num_unique_combinations



dados.info()

# 2. Substituir '-' por NaN em todas as colunas
dados.replace('-', np.nan, inplace=True)

"""# AQUI VAMOS FAZER UMA MODELAGEM PARA PEVER O DESGASTE (WEAR)"""

df = dados

X = df[['vc [m/min]', 'f [mm/rev]', 'Fc [N]', 'œÉFc [N]', 'Ff [N]', 'œÉFf [N]', 'rn [¬µm]', 'œÉrn [¬µm]', 'lcut [mm]']]
y = df['Wear']

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
y_encoded = le.fit_transform(y)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred, target_names=le.classes_))
print(confusion_matrix(y_test, y_pred))

import matplotlib.pyplot as plt

importances = model.feature_importances_
plt.barh(X.columns, importances)
plt.xlabel("Feature Importance")
plt.title("Random Forest - Import√¢ncia das Vari√°veis")
plt.show()



import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import numpy as np

# Exemplo: carregando os dados
# df = pd.read_csv('seus_dados.csv')

# Sele√ß√£o de vari√°veis num√©ricas (ajuste conforme seus dados reais)
X = df[['vc [m/min]', 'f [mm/rev]', 'Fc [N]', 'œÉFc [N]', 'Ff [N]', 'œÉFf [N]', 'rn [¬µm]', 'œÉrn [¬µm]', 'lcut [mm]']]

# Codificando a vari√°vel resposta
le = LabelEncoder()
y = le.fit_transform(df['Wear'])  # L=0, M=1, H=2 (por exemplo)

# Divis√£o treino/teste
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)

# Modelo de regress√£o log√≠stica multinomial
model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)
model.fit(X_train, y_train)

# Coeficientes
classes = le.classes_
coefs = model.coef_  # shape (n_classes, n_features)
intercepts = model.intercept_

# Exibindo as equa√ß√µes
print("EQUA√á√ïES DE PROBABILIDADE PARA CADA CLASSE (L, M, H):\n")

for idx, cls in enumerate(classes):
    eq = f"P(Wear={cls}) = exp({intercepts[idx]:.3f}"
    for i, col in enumerate(X.columns):
        coef = coefs[idx][i]
        eq += f" + {coef:.3f}*{col}"
    eq += ") / DENOMINADOR"
    print(eq)
    print()

# Exemplo de previs√£o de probabilidades para o conjunto de teste
probs = model.predict_proba(X_test)

# Mostrando a probabilidade das 5 primeiras amostras
for i in range(5):
    print(f"Amostra {i+1}: {dict(zip(classes, probs[i]))}")

import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
import statsmodels.api as sm

# Exemplo: carregando os dados
# df = pd.read_csv('seus_dados.csv')

# Sele√ß√£o de vari√°veis num√©ricas
X = df[['vc [m/min]', 'f [mm/rev]', 'Fc [N]', 'œÉFc [N]', 'Ff [N]', 'œÉFf [N]', 'rn [¬µm]', 'œÉrn [¬µm]', 'lcut [mm]']]

# Codificando a vari√°vel resposta
le = LabelEncoder()
y = le.fit_transform(df['Wear'])  # L=0, M=1, H=2 (por exemplo)
classes = le.classes_

# Divis√£o treino/teste
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)

# --- MODELO SKLEARN (para obten√ß√£o das equa√ß√µes)
model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)
model.fit(X_train, y_train)

# Coeficientes
coefs = model.coef_
intercepts = model.intercept_

print("EQUA√á√ïES DE PROBABILIDADE PARA CADA CLASSE (L, M, H):\n")
for idx, cls in enumerate(classes):
    eq = f"P(Wear={cls}) = exp({intercepts[idx]:.3f}"
    for i, col in enumerate(X.columns):
        coef = coefs[idx][i]
        eq += f" + {coef:.3f}*{col}"
    eq += ") / DENOMINADOR"
    print(eq)
    print()

# Exemplo de previs√£o de probabilidades
probs = model.predict_proba(X_test)
for i in range(5):
    print(f"Amostra {i+1}: {dict(zip(classes, probs[i]))}")

# --- NORMALIZA√á√ÉO PARA STATSMODELS
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Adiciona constante (intercepto)
X_sm = sm.add_constant(X_scaled)

# Modelo estat√≠stico
model_sm = sm.MNLogit(y, X_sm)
result = model_sm.fit()

# Mostra os coeficientes com signific√¢ncia estat√≠stica
print("\n=== AN√ÅLISE ESTAT√çSTICA DETALHADA (p-values, z-score) ===\n")
print(result.summary())

from statsmodels.stats.outliers_influence import variance_inflation_factor

vif = pd.DataFrame()
vif["feature"] = X.columns
vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
print(vif)

X_reduced = X.drop(columns=['Fc [N]', 'f [mm/rev]', 'Ff [N]', 'rn [¬µm]', 'œÉrn [¬µm]', 'lcut [mm]'])

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
import statsmodels.api as sm

# Exemplo: carregando os dados
# df = pd.read_csv('seus_dados.csv')

# Remover classe 'H'
df_filtered = df[df['Wear'] != 'H'].copy()

# Vari√°veis de entrada com VIF aceit√°vel
X = df_filtered[['vc [m/min]', 'œÉFc [N]', 'œÉFf [N]']]

# Codificar vari√°vel alvo (L = 0, M = 1)
le = LabelEncoder()
y = le.fit_transform(df_filtered['Wear'])  # L = 0, M = 1

# Normalizar
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = sm.add_constant(X_scaled)

# Regress√£o log√≠stica bin√°ria
model = sm.Logit(y, X_scaled)
result = model.fit()

# Resultado
print("\n=== Regress√£o log√≠stica bin√°ria: Wear M (1) vs L (0) ===\n")
print(result.summary())

# Extrair coeficientes
params = result.params
intercept = params[0]
coef_names = ['vc [m/min]', 'œÉFc [N]', 'œÉFf [N]']
coefs = params[1:]

# Montar equa√ß√£o
eq = f"P(Wear = M) = 1 / (1 + exp(-({intercept:.3f}"
for name, coef in zip(coef_names, coefs):
    eq += f" + {coef:.3f}*{name}"
eq += ")))"

print("\n=== EQUA√á√ÉO DE REGRESS√ÉO LOG√çSTICA ===")
print(eq)

"""# SEM H E COM TODAS AS VERIAVEIS"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
import statsmodels.api as sm

# Exemplo: df = pd.read_csv('seus_dados.csv')

# 1. Filtrar apenas classes L e M
df_filtered = df[df['Wear'].isin(['L', 'M'])].copy()

# 2. Selecionar todas as vari√°veis num√©ricas
X = df_filtered[['vc [m/min]', 'f [mm/rev]', 'Fc [N]', 'œÉFc [N]', 'Ff [N]', 'œÉFf [N]', 'rn [¬µm]', 'œÉrn [¬µm]', 'lcut [mm]']]

# 3. Codificar vari√°vel alvo (L = 0, M = 1)
le = LabelEncoder()
y = le.fit_transform(df_filtered['Wear'])  # L=0, M=1

# 4. Normalizar e adicionar intercepto
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = sm.add_constant(X_scaled)

# 5. Ajustar o modelo log√≠stico bin√°rio
model = sm.Logit(y, X_scaled)
result = model.fit()

# 6. Mostrar an√°lise estat√≠stica
print("\n=== RESULTADOS DA REGRESS√ÉO LOG√çSTICA BIN√ÅRIA: M (1) vs L (0) ===\n")
print(result.summary())

# 7. Gerar equa√ß√£o interpret√°vel
params = result.params
intercept = params[0]
coef_names = X.columns
coefs = params[1:]

eq = f"P(Wear = M) = 1 / (1 + exp(-({intercept:.3f}"
for name, coef in zip(coef_names, coefs):
    eq += f" + {coef:.3f}*{name}"
eq += ")))"

print("\n=== EQUA√á√ÉO DE REGRESS√ÉO LOG√çSTICA BIN√ÅRIA ===")
print(eq)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder, StandardScaler
import statsmodels.api as sm
from sklearn.metrics import roc_curve, auc

# Dados simulados para demonstra√ß√£o (substitua pelo seu DataFrame real `df`)
np.random.seed(42)
size = 282
df = pd.DataFrame({
    'Wear': np.random.choice(['L', 'M'], size=size, p=[0.5, 0.5]),
    'vc [m/min]': np.random.normal(120, 10, size),
    'f [mm/rev]': np.random.normal(0.3, 0.05, size),
    'Fc [N]': np.random.normal(800, 100, size),
    'œÉFc [N]': np.random.normal(10, 2, size),
    'Ff [N]': np.random.normal(200, 30, size),
    'œÉFf [N]': np.random.normal(5, 1, size),
    'rn [¬µm]': np.random.normal(15, 5, size),
    'œÉrn [¬µm]': np.random.normal(1.2, 0.3, size),
    'lcut [mm]': np.random.normal(100, 20, size)
})

# 1. Filtrar apenas classes L e M
df_filtered = df[df['Wear'].isin(['L', 'M'])].copy()

# 2. Selecionar todas as vari√°veis num√©ricas
X = df_filtered[['vc [m/min]', 'f [mm/rev]', 'Fc [N]', 'œÉFc [N]', 'Ff [N]', 'œÉFf [N]', 'rn [¬µm]', 'œÉrn [¬µm]', 'lcut [mm]']]

# 3. Codificar vari√°vel alvo (L = 0, M = 1)
le = LabelEncoder()
y = le.fit_transform(df_filtered['Wear'])  # L=0, M=1

# 4. Normalizar e adicionar intercepto
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = sm.add_constant(X_scaled)

# 5. Ajustar o modelo log√≠stico bin√°rio
model = sm.Logit(y, X_scaled)
result = model.fit()

# 6. Prever probabilidades para o conjunto de dados
pred_probs = result.predict(X_scaled)

# 7. Curva ROC
fpr, tpr, _ = roc_curve(y, pred_probs)
roc_auc = auc(fpr, tpr)

# Plot ROC
plt.figure(figsize=(6, 4))
plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random classifier')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - Logistic Regression')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# 8. Coeficientes com barras
params = result.params[1:]  # exclude intercept
variables = X.columns
coef_df = pd.DataFrame({'Variable': variables, 'Coefficient': params})
plt.figure(figsize=(8, 3))
sns.barplot(x='Coefficient', y='Variable', data=coef_df, palette='viridis')
plt.title('Logistic Regression Coefficients')
plt.grid(False)
plt.tight_layout()
plt.show()







import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
import statsmodels.api as sm

# Exemplo: carregando os dados
# df = pd.read_csv('seus_dados.csv')

# Sele√ß√£o das vari√°veis com baixo VIF
X = df[['vc [m/min]', 'œÉFc [N]', 'œÉFf [N]']]

# Codifica√ß√£o do alvo
le = LabelEncoder()
y = le.fit_transform(df['Wear'])  # L=0, M=1, H=2
classes = le.classes_

# Normaliza√ß√£o
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = sm.add_constant(X_scaled)

# Loop para one-vs-rest
for target_class in np.unique(y):
    y_binary = (y == target_class).astype(int)  # 1 para a classe de interesse, 0 para as outras
    model = sm.Logit(y_binary, X_scaled)
    result = model.fit(disp=False)

    print(f"\n=== Regress√£o log√≠stica para classe '{classes[target_class]}' vs resto ===")
    print(result.summary())

from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
import matplotlib.pyplot as plt

# Binariza as classes para one-vs-rest
y_bin = label_binarize(y_test, classes=[0,1,2])

# ROC por classe
for i, class_name in enumerate(classes):
    fpr, tpr, _ = roc_curve(y_bin[:, i], model.predict_proba(X_test)[:, i])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f'Classe {class_name} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Falso Positivo')
plt.ylabel('Verdadeiro Positivo')
plt.title('Curva ROC por Classe')
plt.legend()
plt.show()

from sklearn.metrics import classification_report
print(classification_report(y_test, model.predict(X_test), target_names=classes))

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, model.predict(X_test))
print(f"Acur√°cia: {accuracy:.3f}")

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test, model.predict(X_test), display_labels=classes)













# Selecionar apenas as colunas desejadas
dados_filtrados = dados[['vc [m/min]', 'f [mm/rev]', 'Fc [N]', 'Wear']]

# Exibir os tipos das colunas selecionadas
print("\nTipos das colunas selecionadas:")
print(dados_filtrados.dtypes)

# Exibir as primeiras linhas do DataFrame filtrado
print("\nPr√©via dos dados selecionados:")
print

dados_filtrados['Wear'].value_counts()

# Remover a classe 'H'
dados_filtrados = dados_filtrados[dados_filtrados['Wear'] != 'H']

# Verificar a nova distribui√ß√£o
print("\nNova distribui√ß√£o de 'Wear' ap√≥s remover 'H':")
print(dados_filtrados['Wear'].value_counts())

dados_filtrados

dados_filtrados.info()

import matplotlib.pyplot as plt
import seaborn as sns

# Criar a figura com 3 subgr√°ficos na horizontal
fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True)  # Compartilhar eixo Y para melhor compara√ß√£o

# Definir as vari√°veis e os t√≠tulos
variaveis = ['vc [m/min]', 'f [mm/rev]', 'Fc [N]']
titulos = ['Cutting Speed (vc)', 'Feed Rate (f)', 'Cutting Force (Fc)']

# Gerar histogramas
for i, var in enumerate(variaveis):
    sns.histplot(dados_filtrados[var], bins=20, kde=True, color="royalblue", ax=axes[i])
    axes[i].set_title(titulos[i], fontsize=16, fontweight="bold")
    axes[i].set_xlabel("")  # Remover r√≥tulo do eixo X
    axes[i].set_ylabel("Frequency", fontsize=14)  # Manter r√≥tulo apenas no eixo Y
    axes[i].tick_params(axis='both', labelsize=12)

# Ajustar layout
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Criar a figura com 3 subgr√°ficos na vertical, sem compartilhar eixo X
fig, axes = plt.subplots(3, 1, figsize=(3, 7))

# Definir as vari√°veis e os t√≠tulos
variaveis = ['vc [m/min]', 'f [mm/rev]', 'Fc [N]']
titulos = ['Cutting Speed (vc)', 'Feed Rate (f)', 'Cutting Force (Fc)']

# Gerar boxplots com escalas individuais e cor cinza claro
for i, var in enumerate(variaveis):
    sns.boxplot(x=dados_filtrados[var], ax=axes[i], color="lightgray", orient="h", width=0.5)
    axes[i].set_title(titulos[i], fontsize=16)
    axes[i].set_xlabel(var, fontsize=14)
    axes[i].tick_params(axis='both', labelsize=12)

# Ajustar layout
plt.tight_layout()
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np

# Criar uma fun√ß√£o para anotar a correla√ß√£o nos gr√°ficos superiores
def annotate_correlation(x, y, **kwargs):
    corr = np.corrcoef(x, y)[0, 1]  # Calcula a correla√ß√£o de Pearson
    ax = plt.gca()
    ax.annotate(f"r = {corr:.2f}", xy=(0.5, 0.9), xycoords=ax.transAxes,
                ha="center", fontsize=16, color="red", fontweight="bold")

# Ajustar o estilo e tamanho da figura
sns.set_context("notebook", rc={"axes.labelsize": 16, "xtick.labelsize": 16, "ytick.labelsize": 16,
                                "legend.fontsize": 16, "figure.figsize": (8, 8)})

# Selecionar apenas as vari√°veis desejadas
dados_selecionados = dados_filtrados[['vc [m/min]', 'f [mm/rev]', 'Fc [N]', 'Wear']]

# Criar o pairplot com a vari√°vel Wear como hue (cor) e incluir linhas de densidade
g = sns.pairplot(dados_selecionados, hue="Wear", diag_kind="kde", markers=["o", "o"],
                 plot_kws={"alpha": 0.7}, diag_kws={"shade": True, "linewidth": 2})

# Adicionar linhas de densidade (KDE Contours) nos gr√°ficos de dispers√£o
for i, j in zip(*np.triu_indices_from(g.axes, k=1)):  # Apenas na metade superior
    sns.kdeplot(x=dados_selecionados.iloc[:, j], y=dados_selecionados.iloc[:, i], ax=g.axes[i, j],
                levels=6, color="gray", linewidths=1.2, alpha=0.6)

# Ajustar o tamanho dos r√≥tulos dos eixos, t√≠tulos e legendas manualmente
for ax in g.axes.flatten():
    if ax is not None:
        ax.xaxis.label.set_size(16)  # Fonte do r√≥tulo do eixo X
        ax.yaxis.label.set_size(16)  # Fonte do r√≥tulo do eixo Y
        ax.tick_params(axis='both', labelsize=16)  # Fonte dos ticks dos eixos

# Ajustar a legenda
g._legend.set_bbox_to_anchor((1, 0.5))  # Posicionar melhor a legenda
g._legend.set_title("Wear", prop={'size': 18, 'weight': 'bold'})  # Aumentar e negritar "Wear"

# Ajustar a fonte dos r√≥tulos da legenda
for text in g._legend.texts:
    text.set_fontsize(16)

# Adicionar as anota√ß√µes de correla√ß√£o nos gr√°ficos superiores
for i, j in zip(*np.triu_indices_from(g.axes, k=1)):
    g.axes[i, j].annotate(f"r = {np.corrcoef(dados_selecionados.iloc[:, j], dados_selecionados.iloc[:, i])[0, 1]:.2f}",
                           xy=(0.5, 0.9), xycoords=g.axes[i, j].transAxes,
                           ha="center", fontsize=16, color="purple", fontweight="bold")

plt.show()

from sklearn.cluster import KMeans
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Selecionar apenas as vari√°veis de entrada
X_cluster = dados_filtrados[['vc [m/min]', 'f [mm/rev]', 'Fc [N]']]

# Aplicar K-Means com 2 clusters (pois temos 2 classes em Wear)
kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
dados_filtrados['Cluster_KMeans'] = kmeans.fit_predict(X_cluster)

# Visualizar os clusters comparados com Wear
plt.figure(figsize=(3, 2))
sns.scatterplot(x=dados_filtrados['vc [m/min]'], y=dados_filtrados['Fc [N]'],
                hue=dados_filtrados['Cluster_KMeans'], palette="Set1", marker="o", edgecolor="k")
plt.title("K-Means Clusters Compared with Wear")
plt.xlabel("vc [m/min]")
plt.ylabel("Fc [N]")
plt.legend(title="Cluster")
plt.grid()
plt.show()

from sklearn.cluster import KMeans
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Selecionar apenas as vari√°veis de entrada
X_cluster = dados_filtrados[['vc [m/min]', 'f [mm/rev]', 'Fc [N]']]

# Aplicar K-Means com 2 clusters
kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)
dados_filtrados['Cluster_KMeans'] = kmeans.fit_predict(X_cluster)

# Verificar m√©dias dos clusters para identificar padr√µes distintos
cluster_means = dados_filtrados.groupby('Cluster_KMeans')[['vc [m/min]', 'f [mm/rev]', 'Fc [N]']].mean()
print("M√©dias dos clusters:\n", cluster_means)

# Mapear clusters para as classes verdadeiras (L e M) com base nas m√©dias
# O cluster com maior for√ßa de corte (Fc [N]) provavelmente representa a classe M (desgaste maior)
if cluster_means.loc[0, 'Fc [N]'] > cluster_means.loc[1, 'Fc [N]']:
    cluster_mapping = {0: 'M', 1: 'L'}
else:
    cluster_mapping = {0: 'L', 1: 'M'}

# Aplicar o mapeamento
dados_filtrados['Cluster_Label'] = dados_filtrados['Cluster_KMeans'].map(cluster_mapping)

# Verificar se os clusters foram mapeados corretamente
print("Cluster Mapping:", cluster_mapping)
print(dados_filtrados[['Cluster_KMeans', 'Wear', 'Cluster_Label']].head())

# Visualizar os clusters comparados com Wear
plt.figure(figsize=(4, 3))
sns.scatterplot(x=dados_filtrados['vc [m/min]'], y=dados_filtrados['Fc [N]'],
                hue=dados_filtrados['Cluster_Label'], palette="Set1", marker="o", edgecolor="k")
plt.title("K-Means Clusters Compared with Wear", fontsize=14)
plt.xlabel("vc [m/min]")
plt.ylabel("Fc [N]")
plt.legend(title="Cluster", fontsize=8)
plt.grid()
plt.show()

from sklearn.cluster import KMeans
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Selecionar as vari√°veis para clustering (f e Fc)
X_cluster_f_fc = dados_filtrados[['f [mm/rev]', 'Fc [N]']]

# Aplicar K-Means com 2 clusters
kmeans_f_fc = KMeans(n_clusters=2, random_state=42, n_init=10)
dados_filtrados['Cluster_KMeans_f_fc'] = kmeans_f_fc.fit_predict(X_cluster_f_fc)

# Verificar m√©dias dos clusters para identificar padr√µes distintos
cluster_means_f_fc = dados_filtrados.groupby('Cluster_KMeans_f_fc')[['f [mm/rev]', 'Fc [N]']].mean()
print("M√©dias dos clusters (f vs Fc):\n", cluster_means_f_fc)

# Mapear clusters para as classes verdadeiras (L e M) com base nas m√©dias
if cluster_means_f_fc.loc[0, 'Fc [N]'] > cluster_means_f_fc.loc[1, 'Fc [N]']:
    cluster_mapping_f_fc = {0: 'M', 1: 'L'}
else:
    cluster_mapping_f_fc = {0: 'L', 1: 'M'}

# Aplicar o mapeamento
dados_filtrados['Cluster_Label_f_fc'] = dados_filtrados['Cluster_KMeans_f_fc'].map(cluster_mapping_f_fc)

# Visualizar os clusters comparados com Wear
plt.figure(figsize=(4, 3))
sns.scatterplot(x=dados_filtrados['f [mm/rev]'], y=dados_filtrados['Fc [N]'],
                hue=dados_filtrados['Cluster_Label_f_fc'], palette="Set1", marker="o", edgecolor="k")
plt.title("K-Means Clusters (Feed Rate vs Cutting Force)", fontsize=14)
plt.xlabel("f [mm/rev]")
plt.ylabel("Fc [N]")
plt.legend(title="Cluster", fontsize=8)
plt.grid()
plt.show()

"""L: Low (Baixo) ‚Äì Indica um n√≠vel baixo de desgaste.

M: Medium (M√©dio) ‚Äì Indica um n√≠vel m√©dio de desgaste.


"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# 1Ô∏è‚É£ Verificar os dados
print("\nTipos das colunas selecionadas:")
print(dados_filtrados.dtypes)

# 2Ô∏è‚É£ Codificar a vari√°vel alvo (Wear)
le = LabelEncoder()
dados_filtrados['Wear_encoded'] = le.fit_transform(dados_filtrados['Wear'])

# Verificar a codifica√ß√£o
print("\nCodifica√ß√£o de 'Wear':")
print(dict(zip(le.classes_, le.transform(le.classes_))))

# 2Ô∏è‚É£ Selecionar 20 amostras aleat√≥rias para previs√£o
dados_para_prever = dados_filtrados.sample(n=20, random_state=42)
dados_filtrados = dados_filtrados.drop(dados_para_prever.index)  # Remover essas amostras do treino/teste

# 4Ô∏è‚É£ Separar vari√°veis independentes (X) e dependente (y)
X = dados_filtrados[['vc [m/min]', 'f [mm/rev]', 'Fc [N]']]
y = dados_filtrados['Wear_encoded']

# 5Ô∏è‚É£ Dividir em treino e teste (80% treino, 20% teste, com estratifica√ß√£o)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 6Ô∏è‚É£ Balanceamento com SMOTE para lidar com a baixa quantidade de classe 'H'
smote = SMOTE(random_state=42, k_neighbors=2)  # Reduzindo k_neighbors para evitar erro
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# 7Ô∏è‚É£ Normalizar os dados (StandardScaler)
scaler = StandardScaler()
X_train_res_scaled = scaler.fit_transform(X_train_res)
X_test_scaled = scaler.transform(X_test)

"""# **Criar modelos**"""

from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from lightgbm import LGBMClassifier
from sklearn.metrics import classification_report

# üîπ 8. Definir os hiperpar√¢metros para cada modelo
param_rf = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 20], 'min_samples_split': [5, 10], 'min_samples_leaf': [2, 5]}
param_svm = {'C': [0.1, 1, 10], 'kernel': ['rbf', 'linear']}
param_lr = {'C': [0.1, 1, 10], 'max_iter': [200, 500]}
param_lgbm = {'num_leaves': [31, 50], 'learning_rate': [0.01, 0.1], 'n_estimators': [50, 100, 200]}

# üîπ 9. Criar os modelos com hiperpar√¢metros otimizados via GridSearch
modelos = {
    "Random Forest": GridSearchCV(RandomForestClassifier(random_state=42), param_rf, cv=StratifiedKFold(n_splits=10), scoring='accuracy'),
    "SVM": GridSearchCV(SVC(probability=True, class_weight='balanced', random_state=42), param_svm, cv=StratifiedKFold(n_splits=10), scoring='accuracy'),
    "Logistic Regression": GridSearchCV(LogisticRegression(class_weight='balanced', random_state=42), param_lr, cv=StratifiedKFold(n_splits=10), scoring='accuracy'),
    "LightGBM": GridSearchCV(LGBMClassifier(random_state=42), param_lgbm, cv=StratifiedKFold(n_splits=10), scoring='accuracy')
}

# üîπ 10. Treinar, avaliar e validar com cross-validation
resultados = {}

for nome, modelo in modelos.items():
    print(f"\nüîπ Treinando {nome}...")

    # Treinar o modelo com os melhores hiperpar√¢metros
    modelo.fit(X_train_res_scaled, y_train_res)
    melhor_modelo = modelo.best_estimator_

    # Previs√µes no treino e teste
    y_train_pred = melhor_modelo.predict(X_train_res_scaled)
    y_test_pred = melhor_modelo.predict(X_test_scaled)

    # Valida√ß√£o cruzada
    scores = cross_val_score(melhor_modelo, X_train_res_scaled, y_train_res, cv=StratifiedKFold(n_splits=10), scoring='accuracy')
    media_cv = scores.mean()

    # Exibir m√©tricas
    print(f"\nüìå Melhor Modelo para {nome}: {modelo.best_params_}")
    print(f"\nüìå M√©tricas para {nome} (TREINO):")
    print(classification_report(y_train_res, y_train_pred, target_names=le.classes_))

    print(f"\nüìå M√©tricas para {nome} (TESTE):")
    print(classification_report(y_test, y_test_pred, target_names=le.classes_))

    print(f"\nüìå Valida√ß√£o Cruzada (M√©dia de Acur√°cia): {media_cv:.4f}")

    # Armazenar resultados
    resultados[nome] = {
        "Melhor Modelo": modelo.best_params_,
        "Valida√ß√£o Cruzada": media_cv,
        "Treino": classification_report(y_train_res, y_train_pred, target_names=le.classes_, output_dict=True),
        "Teste": classification_report(y_test, y_test_pred, target_names=le.classes_, output_dict=True)
    }

from scipy.interpolate import make_interp_spline

import seaborn as sns
import numpy as np
from sklearn.metrics import roc_curve, auc
from scipy.interpolate import make_interp_spline
import matplotlib.pyplot as plt

# üîπ 1Ô∏è‚É£ ROC-AUC CURVES FOR MODELS (Smoothed)
plt.figure(figsize=(3, 2))

for name, model in modelos.items():
    best_model = model.best_estimator_
    y_test_prob = best_model.predict_proba(X_test_scaled)[:, 1]  # Probabilities for the positive class (M)
    fpr, tpr, _ = roc_curve(y_test, y_test_prob)  # FPR = False Positive Rate, TPR = True Positive Rate
    roc_auc = auc(fpr, tpr)

    # Remove duplicate values from fpr (X) and adjust tpr (Y)
    fpr_unique, indices = np.unique(fpr, return_index=True)
    tpr_unique = tpr[indices]


# Criando pontos intermedi√°rios para suaviza√ß√£o
    fpr_smooth = np.linspace(fpr_unique.min(), fpr_unique.max(), 32)
    tpr_smooth = make_interp_spline(fpr_unique, tpr_unique, k=0)(fpr_smooth)  # Interpola√ß√£o c√∫bica

    plt.plot(fpr_smooth, tpr_smooth, label=f"{name} (AUC = {roc_auc:.2f})")

plt.plot([0, 1], [0, 1], 'k--', alpha=0.6)  # Diagonal line (random classification)
plt.xlabel('False Positive Rate', fontsize=10)
plt.ylabel('True Positive Rate', fontsize=10)
plt.title('ROC Curves of the Models', fontsize=10)
#plt.legend(loc="lower right", fontsize=8)
plt.grid()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# üîπ 2Ô∏è‚É£ CONFUSION MATRIX FOR EACH MODEL (ENGLISH + SMALLER FONT)
fig, axes = plt.subplots(1, 4, figsize=(12, 3))

for ax, (name, model) in zip(axes, modelos.items()):
    best_model = model.best_estimator_
    y_test_pred = best_model.predict(X_test_scaled)

    cm = confusion_matrix(y_test, y_test_pred)

    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=le.classes_, yticklabels=le.classes_, ax=ax,
                annot_kws={"size": 10})  # Reduce annotation font size

    ax.set_title(f"Confusion Matrix - {name}", fontsize=7)  # Reduce title font size
    ax.set_xlabel("Predicted", fontsize=10)  # Reduce x-label font size
    ax.set_ylabel("Actual", fontsize=10)  # Reduce y-label font size
    ax.tick_params(axis='both', which='major', labelsize=10)  # Reduce tick labels

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import learning_curve, StratifiedKFold

# üîπ 3Ô∏è‚É£ LEARNING CURVES (SHOWING 10 POINTS)
fig, axes = plt.subplots(2, 2, figsize=(8, 5))  # 2x2 layout for better spacing

axes = axes.ravel()  # Flatten axes array for easier iteration

for ax, (name, model) in zip(axes, modelos.items()):
    best_model = model.best_estimator_

    # Define 10 points for the training set
    train_sizes, train_scores, test_scores = learning_curve(
        best_model, X_train_res_scaled, y_train_res,
        train_sizes=np.linspace(0.1, 1.0, 10),  # 10 points
        cv=StratifiedKFold(n_splits=10),
        scoring='accuracy'
    )

    train_mean = np.mean(train_scores, axis=1)
    test_mean = np.mean(test_scores, axis=1)

    ax.plot(train_sizes, train_mean, 'o-', label="Training")
    ax.plot(train_sizes, test_mean, 'o-', label="Validation")

    ax.set_title(f"Learning Curve - {name}", fontsize=14)
    ax.set_xlabel("Training Size", fontsize=12)
    ax.set_ylabel("Accuracy", fontsize=12)
    ax.legend(fontsize=12)
    ax.tick_params(axis='both', labelsize=12)  # Reduce tick label size
    ax.grid(False)

# Adjust layout to prevent overlapping
plt.tight_layout()
plt.show()

# üîü Previs√µes nos dados separados para teste real
X_para_prever = dados_para_prever[['vc [m/min]', 'f [mm/rev]', 'Fc [N]']]
X_para_prever_scaled = scaler.transform(X_para_prever)
df_previsoes = dados_para_prever[['vc [m/min]', 'f [mm/rev]', 'Fc [N]', 'Wear']].rename(columns={'Wear': 'Wear_Real'})

for nome, modelo in modelos.items():
    melhor_modelo = modelo.best_estimator_
    previsoes = melhor_modelo.predict(X_para_prever_scaled)
    df_previsoes[f'Wear_Previsto_{nome}'] = le.inverse_transform(previsoes)

# Instead, use the following to display the DataFrame:
display(df_previsoes)

"""# **Nova abordagem**"""

!pip install lime

import numpy as np
import pandas as pd
from lime.lime_tabular import LimeTabularExplainer
import lightgbm as lgb

# üîπ Treinar LightGBM antes de us√°-lo no LIME
param_lgbm = {'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}

# Criar GridSearchCV para LightGBM
lgbm_grid = GridSearchCV(
    lgb.LGBMClassifier(random_state=42),
    param_grid=param_lgbm,
    cv=StratifiedKFold(n_splits=5),
    scoring='accuracy'
)

# Treinar LightGBM no conjunto de treino
lgbm_grid.fit(X_train_res_scaled, y_train_res)

# Adicionar o melhor modelo LightGBM ao dicion√°rio
modelos["LightGBM"] = lgbm_grid.best_estimator_

# üîπ Criar o LIME Explainer para os dados de treino
explainer = LimeTabularExplainer(
    training_data=np.array(X_train_res_scaled),  # Usar os dados escalados
    feature_names=X.columns.tolist(),
    class_names=list(le.classes_),
    mode='classification'
)

# üîπ Selecionar uma amostra para explica√ß√£o
i = 0  # √çndice da amostra no conjunto de teste
data_instance = X_test_scaled[i]

# üîπ Criar um dicion√°rio para armazenar os pesos das features para cada modelo
lime_results = {}

# üîπ Explicar cada modelo com LIME
for model_name, model in modelos.items():
    print(f"\nüîπ Generating LIME explanation for {model_name}...")

    # Gerar explica√ß√£o para a amostra
    exp = explainer.explain_instance(
        data_row=data_instance,
        predict_fn=model.predict_proba  # Fun√ß√£o de predi√ß√£o
    )

    # Extrair pesos das features e armazenar no dicion√°rio
    feature_importance = {feature: weight for feature, weight in exp.as_list()}
    lime_results[model_name] = feature_importance

# üîπ Converter os resultados para um DataFrame
df_lime_importance = pd.DataFrame(lime_results).T

df_lime_importance

import matplotlib.pyplot as plt
import numpy as np

# Data
models = ["Random Forest", "SVM", "Logistic Regression", "LightGBM"]
features = ["f [mm/rev] ‚â§ -0.81", "Fc [N] ‚â§ -0.87", "-0.66 < vc [m/min] ‚â§ -0.38"]

values = np.array([
    [-0.324841, -0.286686, -0.026672],
    [-0.010898, -0.504096, 0.003120],
    [0.191452, -0.628184, -0.021337],
    [-0.014794, -0.612212, -0.089924]
])

# Colors for bars
colors = ['royalblue', 'darkorange', 'mediumseagreen', 'crimson']

# Plot setup
fig, axes = plt.subplots(len(models), 1, figsize=(8, 5), sharex=True)

for i, (ax, model) in enumerate(zip(axes, models)):
    ax.barh(features, values[i], color=colors[i], alpha=0.7, edgecolor='black')

    # Add value annotations on the bars
    for j, v in enumerate(values[i]):
        ax.text(v, j, f"{v:.3f}", va='center', ha='left' if v >= 0 else 'right', fontsize=12)

    ax.set_title(model, fontsize=14)
    ax.axvline(x=0, color='black', linestyle='--', linewidth=1)
    ax.set_yticklabels(features, fontsize=12)

# Set x-axis label and limits
plt.xlabel("Feature Contribution (LIME)", fontsize=14)
plt.xticks(fontsize=12)
plt.xlim(-0.7, 0.3)

# Adjust layout
plt.tight_layout(rect=[0, 0, 1, 0.95])

# Show plot
plt.show()

dados_filtrados

print(y_train_res.value_counts())

import lightgbm as lgb
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# üîπ Renomear colunas para remover caracteres especiais
X_train_filtered = X_train.drop(columns=['vc [m/min]'], errors='ignore').rename(
    columns={"f [mm/rev]": "feed_rate", "Fc [N]": "cutting_force"}
)
X_test_filtered = X_test.drop(columns=['vc [m/min]'], errors='ignore').rename(
    columns={"f [mm/rev]": "feed_rate", "Fc [N]": "cutting_force"}
)

# üîπ Hiperpar√¢metros ajustados para os modelos
param_rf = {'n_estimators': [50, 100], 'max_depth': [5, 10]}
param_svm = {'C': [1, 10], 'kernel': ['rbf']}
param_lr = {'C': [10], 'max_iter': [200]}
param_lgb = {'num_leaves': [31, 50], 'learning_rate': [0.01, 0.1], 'n_estimators': [50, 100]}

# üîπ Criar os modelos com GridSearchCV
modelos_filtrados = {
    "Random Forest": GridSearchCV(RandomForestClassifier(random_state=42), param_rf, cv=StratifiedKFold(n_splits=5), scoring='accuracy'),
    "SVM": GridSearchCV(SVC(probability=True, class_weight='balanced', random_state=42), param_svm, cv=StratifiedKFold(n_splits=5), scoring='accuracy'),
    "Logistic Regression": GridSearchCV(LogisticRegression(class_weight='balanced', random_state=42), param_lr, cv=StratifiedKFold(n_splits=5), scoring='accuracy'),
    "LightGBM": GridSearchCV(lgb.LGBMClassifier(random_state=42), param_lgb, cv=StratifiedKFold(n_splits=5), scoring='accuracy')
}

# üîπ Treinar, avaliar e validar com cross-validation
resultados_filtrados = {}

for nome, modelo in modelos_filtrados.items():
    print(f"\nüîπ Treinando {nome} sem vc [m/min]...")
    modelo.fit(X_train_filtered, y_train)
    melhor_modelo = modelo.best_estimator_

    # Previs√µes no treino e teste
    y_train_pred = melhor_modelo.predict(X_train_filtered)
    y_test_pred = melhor_modelo.predict(X_test_filtered)

    # Ajuste de threshold para SVM, Logistic Regression e LightGBM
    if nome in ["SVM", "Logistic Regression", "LightGBM"]:
        probs = melhor_modelo.predict_proba(X_test_filtered)[:, 1]
        threshold = 0.4
        y_test_pred = (probs > threshold).astype(int)

    # Valida√ß√£o cruzada
    scores = cross_val_score(melhor_modelo, X_train_filtered, y_train, cv=StratifiedKFold(n_splits=10), scoring='accuracy')
    media_cv = scores.mean()

    # Obter m√©tricas
    print(f"\nüìå Melhor Modelo para {nome}: {modelo.best_params_}")
    print(f"\nüìå M√©tricas para {nome} (TREINO):")
    print(classification_report(y_train, y_train_pred, target_names=le.classes_))

    print(f"\nüìå M√©tricas para {nome} (TESTE) - Threshold Ajustado: {threshold if nome in ['SVM', 'Logistic Regression', 'LightGBM'] else 'Padr√£o'}")
    print(classification_report(y_test, y_test_pred, target_names=le.classes_))

    print(f"\nüìå Valida√ß√£o Cruzada (M√©dia de Acur√°cia): {media_cv:.4f}")

    # Armazenar resultados
    resultados_filtrados[nome] = {
        "Melhor Modelo": modelo.best_params_,
        "Valida√ß√£o Cruzada": media_cv,
        "Treino": classification_report(y_train, y_train_pred, target_names=le.classes_, output_dict=True),
        "Teste": classification_report(y_test, y_test_pred, target_names=le.classes_, output_dict=True)
    }

# üîπ Reajustar o scaler APENAS com as vari√°veis usadas no novo modelo
scaler_filtrado = StandardScaler()
X_train_res_scaled_filtrado = scaler_filtrado.fit_transform(X_train_res[['f [mm/rev]', 'Fc [N]']])
X_test_scaled_filtrado = scaler_filtrado.transform(X_test[['f [mm/rev]', 'Fc [N]']])

# üîπ Ajustar tamb√©m os dados para previs√£o real
X_para_prever_filtrado = dados_para_prever[['f [mm/rev]', 'Fc [N]']]
X_para_prever_scaled_filtrado = scaler_filtrado.transform(X_para_prever_filtrado)

# Criar DataFrame para armazenar as previs√µes
df_previsoes_filtradas = dados_para_prever[['f [mm/rev]', 'Fc [N]', 'Wear']].rename(columns={'Wear': 'Wear_Real'})

# üîπ Fazer previs√µes para cada modelo ajustado
for nome, modelo in modelos_filtrados.items():
    melhor_modelo = modelo.best_estimator_
    previsoes = melhor_modelo.predict(X_para_prever_scaled_filtrado)
    df_previsoes_filtradas[f'Wear_Previsto_{nome}'] = le.inverse_transform(previsoes)

df_previsoes_filtradas

"""# **Gest√£o de features**"""

df

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
import lightgbm as lgb
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# üîπ 1Ô∏è‚É£ Carregar os dados
df = dados_filtrados # Substituir pelo nome correto

# üîπ 2Ô∏è‚É£ Definir as features e o alvo
# Rename columns to remove special characters and spaces
features_full = ["f_mm_rev", "Fc_N", "vc_m_min"]  # Todas as features, renamed
target = "Wear"  # Substituir pelo nome correto da vari√°vel alvo

# Rename columns in the DataFrame
df = df.rename(columns={
    "f [mm/rev]": "f_mm_rev",
    "Fc [N]": "Fc_N",
    "vc [m/min]": "vc_m_min"
})

# üîπ 3Ô∏è‚É£ Criar vers√µes reduzidas do conjunto de features
features_no_vc = ["f_mm_rev", "Fc_N"]  # Removendo vc
features_no_vc_f = ["Fc_N"]  # Removendo vc e f

# üîπ 4Ô∏è‚É£ Separar os conjuntos de treino e teste
X_full = df[features_full]
X_no_vc = df[features_no_vc]
X_no_vc_f = df[features_no_vc_f]
y = df[target]

X_train_full, X_test_full, y_train, y_test = train_test_split(X_full, y, test_size=0.2, random_state=42, stratify=y)
X_train_no_vc, X_test_no_vc, _, _ = train_test_split(X_no_vc, y, test_size=0.2, random_state=42, stratify=y)
X_train_no_vc_f, X_test_no_vc_f, _, _ = train_test_split(X_no_vc_f, y, test_size=0.2, random_state=42, stratify=y)

# üîπ 5Ô∏è‚É£ Definir os modelos
models = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel="rbf", probability=True, random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=200, random_state=42),
    "LightGBM": lgb.LGBMClassifier(n_estimators=100, random_state=42)
}

# üîπ 6Ô∏è‚É£ Fun√ß√£o para treinar e avaliar os modelos
def evaluate_models(X_train, X_test, y_train, y_test):
    results = []
    for name, model in models.items():
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        results.append({
            "Model": name,
            "Accuracy": accuracy_score(y_test, y_pred),
            "Precision": precision_score(y_test, y_pred, average="macro"),
            "Recall": recall_score(y_test, y_pred, average="macro"),
            "F1-score": f1_score(y_test, y_pred, average="macro")
        })

    return pd.DataFrame(results)

# üîπ 7Ô∏è‚É£ Avalia√ß√£o
df_results_full = evaluate_models(X_train_full, X_test_full, y_train, y_test)
df_results_no_vc = evaluate_models(X_train_no_vc, X_test_no_vc, y_train, y_test)
df_results_no_vc_f = evaluate_models(X_train_no_vc_f, X_test_no_vc_f, y_train, y_test)

#üîπ 8Ô∏è‚É£Exibir Resultados
# Instead of using ace_tools, we can directly display the DataFrame using 'display'
df_results_full["Feature Set"] = "All Features"
df_results_no_vc["Feature Set"] = "Without vc"
df_results_no_vc_f["Feature Set"] = "Without vc & f"

df_final = pd.concat([df_results_full, df_results_no_vc, df_results_no_vc_f])

df_final

"""# **SHAP**"""

import shap
import matplotlib.pyplot as plt
import numpy as np

# Criar um dicion√°rio para armazenar os valores SHAP
shap_explainers = {}
shap_values = {}

for model_name, model in modelos.items():
    print(f"üîπ Calculando SHAP para {model_name}...")

    # Obter o melhor modelo treinado
    best_model = model.best_estimator_

    # Criar o explainer do SHAP com o modelo ajustado
    # Pass X_train (or X_train_res_scaled) instead of X_test_scaled
    # and add check_additivity=False to disable the additivity check
    explainer = shap.Explainer(best_model, X_train_res_scaled)
    shap_values[model_name] = explainer(X_test_scaled)

    # Armazena o explainer
    shap_explainers[model_name] = explainer

# üîπ Gerar Gr√°ficos SHAP

# Gr√°fico de Import√¢ncia Global das Features
for model_name, shap_vals in shap_values.items():
    plt.figure(figsize=(8, 4))
    shap.summary_plot(shap_vals, X_test_scaled, feature_names=X.columns, show=False)
    plt.title(f"SHAP Summary Plot - {model_name}")
    plt.show()

# Gr√°fico de Depend√™ncia para a Feature Mais Importante
for model_name, shap_vals in shap_values.items():
    plt.figure(figsize=(8, 4))
    shap.dependence_plot(
        ind=np.argmax(np.abs(shap_vals.values).mean(axis=0)),
        shap_values=shap_vals.values,
        features=X_test_scaled,
        feature_names=X.columns
    )
    plt.title(f"SHAP Dependence Plot - {model_name}")
    plt.show()

import shap
import matplotlib.pyplot as plt
import numpy as np

# Criar um dicion√°rio para armazenar os valores SHAP
shap_explainers = {}
shap_values = {}

for model_name, model in modelos.items():
    print(f"üîπ Calculando SHAP para {model_name}...")

    # Se o modelo foi otimizado com GridSearchCV, pegue o melhor estimador
    best_model = model.best_estimator_ if hasattr(model, "best_estimator_") else model

    # Verificar se √© um modelo baseado em √°rvores
    if model_name in ["Random Forest", "LightGBM"]:
        explainer = shap.TreeExplainer(best_model)
        shap_vals = explainer.shap_values(X_test_scaled, check_additivity=False)

        # Se shap_values retornar uma lista, selecionamos apenas a classe positiva
        if isinstance(shap_vals, list):
            shap_vals = shap_vals[1]  # Pegamos a classe positiva
    else:
        explainer = shap.KernelExplainer(best_model.predict_proba, X_train_res_scaled[:50])
        shap_vals = explainer.shap_values(X_test_scaled)

        # Para SVM e Logistic Regression, escolhemos a classe positiva
        if isinstance(shap_vals, list):
            shap_vals = shap_vals[1]

    # Armazena os valores SHAP
    shap_explainers[model_name] = explainer
    shap_values[model_name] = shap_vals

# üîπ Gerar Gr√°ficos SHAP

# Gr√°fico de Import√¢ncia Global das Features
for model_name, shap_vals in shap_values.items():
    plt.figure(figsize=(8, 4))

    # Se shap_values for uma lista, selecionar a classe positiva
    if isinstance(shap_vals, list):
        shap_vals = shap_vals[1]

    shap.summary_plot(shap_vals, X_test_scaled, feature_names=X.columns, show=False)
    plt.title(f"SHAP Summary Plot - {model_name}")
    plt.show()

# Gr√°fico de Depend√™ncia para a Feature Mais Importante
for model_name, shap_vals in shap_values.items():
    plt.figure(figsize=(8, 4))

    # Se shap_vals for uma lista, selecionar a classe positiva
    if isinstance(shap_vals, list):
        shap_vals = shap_vals[1]

    # Encontrar a feature mais importante
    most_important_feature_index = np.argmax(np.abs(shap_vals).mean(axis=0))

    # Criar gr√°fico de depend√™ncia SHAP
    shap.dependence_plot(
        ind=most_important_feature_index,
        shap_values=shap_vals,
        features=X_test_scaled,
        feature_names=X.columns
    )
    plt.title(f"SHAP Dependence Plot - {model_name}")
    plt.show()

import shap
import numpy as np
import matplotlib.pyplot as plt

# Criar um dicion√°rio para armazenar os valores SHAP
shap_explainers = {}
shap_values = {}

for model_name, model in modelos.items():
    print(f"üîπ Calculando SHAP para {model_name}...")

    # Se o modelo foi otimizado com GridSearchCV, pegue o melhor estimador
    best_model = model.best_estimator_ if hasattr(model, "best_estimator_") else model

    # Criar explicador SHAP para modelos de √°rvore
    if model_name in ["Random Forest", "LightGBM"]:
        # Remova o argumento check_additivity se n√£o for suportado
        explainer = shap.TreeExplainer(best_model)
        shap_vals = explainer.shap_values(X_test_scaled)

        # Se o SHAP retornar uma lista, pegamos a classe positiva
        if isinstance(shap_vals, list):
            shap_vals = shap_vals[1]

    else:
        # Para modelos que n√£o s√£o de √°rvore, como SVM
        if model_name == "SVM":
            # Usar KernelExplainer para SVM
            explainer = shap.KernelExplainer(best_model.predict_proba, X_train_res_scaled)
            shap_vals = explainer.shap_values(X_test_scaled)
        else:
            # Para outros modelos que n√£o s√£o de √°rvore
            explainer = shap.Explainer(best_model, X_train_res_scaled)
            shap_vals = explainer(X_test_scaled)

    # Armazena os valores SHAP
    shap_explainers[model_name] = explainer
    shap_values[model_name] = shap_vals

# üîπ Gerar Gr√°ficos SHAP
for model_name, shap_vals in shap_values.items():
    plt.figure(figsize=(5, 4))  # Tamanho da figura ajustado para melhor visualiza√ß√£o

    # For√ßar a exibi√ß√£o de todas as vari√°veis e garantir consist√™ncia
    shap.summary_plot(
        shap_vals,
        X_test_scaled,
        feature_names=X.columns,
        show=False,
        plot_size=None,
        max_display=len(X.columns)  # For√ßa a exibi√ß√£o de todas as vari√°veis
    )

    # Personalizar o t√≠tulo e o layout
    plt.title(f"SHAP Summary Plot - {model_name}", fontsize=16, pad=20)
    plt.xlabel("SHAP Value (Impact on Model Output)", fontsize=12)
    plt.ylabel("Features", fontsize=12)
    plt.tight_layout()  # Ajustar o layout para evitar sobreposi√ß√£o
    plt.show()